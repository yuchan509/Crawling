{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import platform, time, urllib, random\n",
    "from selenium import webdriver as wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 설정.\n",
    "# Chrome 브라우저 띠우기.\n",
    "chromedriver ='c:/chromedriver.exe'\n",
    "\n",
    "# Mac 환경.\n",
    "if platform.system() == 'Darwin': \n",
    "    # 맥 PC는 드라이버 있는 위치에서 아래 명령 터미널에서 수행 후 진행.\n",
    "    # $ xattr -d com.apple.quarantine chromedriver\n",
    "    driver = wd.Chrome(chromedriver)\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "# Window 환경.  \n",
    "else:   \n",
    "    driver = wd.Chrome(chromedriver)\n",
    "    driver.implicitly_wait(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이트 로그인 함수.\n",
    "def Login() :\n",
    "    # EveryTime 접속을 위한 자동 로그인 설정.\n",
    "    URL = 'https://everytime.kr/login'\n",
    "    driver.get(URL)\n",
    "    \n",
    "    user_id = input('Input your ID : ')\n",
    "    user_pw = input('Input your Password : ')\n",
    "    driver.find_element_by_name('userid').send_keys(user_id)\n",
    "    driver.find_element_by_name('password').send_keys(user_pw)\n",
    "\n",
    "    # Element 접근.\n",
    "    driver.find_element_by_xpath('//*[@class=\"submit\"]/input').click()\n",
    "    \n",
    "    # Uniform 분포로 부터 랜덤 시간값 설정.\n",
    "    value = random.uniform(3, 7) \n",
    "    time.sleep(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 시에는 입력값 미리 입력시킴으로써 자동 로그인화하고 진행.\n",
    "# 로그인 하기.\n",
    "Login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간표 URL로 이동.\n",
    "driver.find_element_by_xpath('//*[@id=\"menu\"]/li[2]/a').click()\n",
    "value = random.uniform(2, 5) \n",
    "time.sleep(value)\n",
    "\n",
    "# 년도 및 학기 선택 여부 가져오기.\n",
    "year, sem = input('수집하고자 하는 년도와 학기를 입력해주세요. ex) 2021, 1   : 사용자 입력값 : ').split(',')  \n",
    "\n",
    "url = \"https://everytime.kr/timetable/\" + year + '/' + sem\n",
    "value = random.uniform(3, 5) \n",
    "time.sleep(value)\n",
    "driver.get(url)\n",
    "\n",
    "# 수업 목록에서 검색 버튼 클릭.\n",
    "driver.find_element_by_xpath('//*[@id=\"container\"]/ul/li[1]').click()\n",
    "value = random.uniform(2, 5) \n",
    "time.sleep(value)\n",
    "\n",
    "# 처음 뜨는 팝업창 닫기.\n",
    "# 처음 들어가는 것이 아니라면 이 부분은 작동시키지 않음.\n",
    "# river.find_element_by_xpath('//*[@id=\"sheet\"]/ul/li[3]').click()\n",
    "# value = random.uniform(2, 5) \n",
    "# time.sleep(value)\n",
    "\n",
    "\n",
    "# 전공/영역 클릭.\n",
    "driver.find_element_by_xpath('//*[@id=\"subjects\"]/div[1]/a[3]').click()\n",
    "value = random.uniform(2, 5) \n",
    "time.sleep(value)\n",
    "\n",
    "# 2018년도 2학기 부터 전공 버튼 클릭이 존재.\n",
    "# 2018년 1학기 이전은 다른 방식으로 수집하도록 설정할 필요가 있음.\n",
    "# 전공 클릭.\n",
    "driver.find_element_by_xpath('//*[@id=\"subjectCategoryFilter\"]/div/ul/li[4]').click()\n",
    "value = random.uniform(2, 5) \n",
    "time.sleep(value)\n",
    "\n",
    "# 여기서 부터 반복문 수행할 필요가 있음.\n",
    "# 전공 재스크롤 => 전공 선택(이과정이 2번째부터는 필요x) => 선택한 전공 끝까지 스크롤 => 선택 전공 수집 및 저장 => 전공 영역 선택.\n",
    "process1 = True\n",
    "process2 = True\n",
    "while process1 :\n",
    "    \n",
    "    # 데이터 수집 여부 질문.\n",
    "    choice = input('데이터를 수집을 진행하시겠습니까? :').lower()\n",
    "    if choice == '네' or choice == 'yes' :\n",
    "        pass\n",
    "    elif choice == '아니오' or choice == 'no' :\n",
    "        process = False \n",
    "        break\n",
    "    else :\n",
    "        print('정확하게 입력하세요.')\n",
    "        continue\n",
    "    \n",
    "    # 학과 선택.\n",
    "    # 학과 선택을 하면 이에 대응하는 학과 번호를 찾아 사이트를 이동.\n",
    "    sub_num_list = {\n",
    "                     '학과'    : [],\n",
    "                     '학과 ID' : []\n",
    "                        }\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    ul = soup.select('#subjectCategoryFilter > div > ul > ul.unfolded')\n",
    "    for li in ul :\n",
    "        a1 = li.select('li')\n",
    "        for idx, a2 in enumerate(a1) :\n",
    "            a3 = a2.text.strip()\n",
    "            sub_num_list['학과'].append(a3)\n",
    "            sub_num_list['학과 ID'].append(idx + 1)\n",
    "    data = pd.DataFrame(sub_num_list)\n",
    "    \n",
    "    # while process2 :\n",
    "    sub_name = input('학과를 선택하십시오. : ').lower()\n",
    "    info = data['학과'].values\n",
    "\n",
    "    if any(sub_name == i for i in info) :\n",
    "        print('수집을 시작합니다.')\n",
    "        break\n",
    "    else : \n",
    "        print('해당되는 과목명이 존재하지 않습니다.')\n",
    "        continue    \n",
    "\n",
    "    select_data = data[data['학과'] == sub_name]\n",
    "    sub_num = select_data['학과 ID'].values[0]\n",
    "\n",
    "    # 전공 목록 스크롤 내리기.\n",
    "    element_list = []\n",
    "    for i in range(1, 148) :\n",
    "        element = driver.find_elements_by_css_selector(f'#subjectCategoryFilter > div > ul > ul.unfolded > li:nth-child({i})')\n",
    "        element_list.append(element)\n",
    "\n",
    "    for i in range(1, 150, 30) :\n",
    "        current_cnt = element_list[i][0]\n",
    "        driver.execute_script('arguments[0].scrollIntoView(true);', current_cnt)\n",
    "        value = random.uniform(1, 2) \n",
    "        time.sleep(value)\n",
    "\n",
    "    # 끝나는 시점 설정.\n",
    "    result = element_list[-1][0]\n",
    "\n",
    "    if result == current_cnt :\n",
    "        break\n",
    "    else :\n",
    "        result = current_cnt\n",
    "\n",
    "    driver.find_element_by_xpath(f'//*[@id=\"subjectCategoryFilter\"]/div/ul/ul[3]/li[{sub_num}]').click()\n",
    "    value = random.uniform(2, 5) \n",
    "    time.sleep(value)\n",
    "\n",
    "    # 검색하여 들어간 해당과목 스크롤 맨아래까지 내리기.\n",
    "    cnt = 0\n",
    "    while True :\n",
    "        element = driver.find_elements_by_css_selector(\"#subjects > div.list > table > tbody > tr\")\n",
    "        end     = element[-1]\n",
    "        driver.execute_script('arguments[0].scrollIntoView(true);', end)\n",
    "        value   = random.uniform(1, 2) \n",
    "        time.sleep(value)\n",
    "\n",
    "        # 끝나는 시점.\n",
    "        current_count = len(element)\n",
    "        if cnt == current_count :\n",
    "            break\n",
    "        cnt = current_count\n",
    "\n",
    "    # 과목에 관한 자료 수집.\n",
    "    html   = driver.page_source\n",
    "    soup   = BeautifulSoup(html, 'html.parser')\n",
    "    tr_tag = soup.select('#subjects > div.list > table > tbody > tr')\n",
    "\n",
    "    subjet_dict = {\n",
    "                    '학과'       : [],\n",
    "                    '학년'       : [],\n",
    "                    '구분'       : [],\n",
    "                    '과목코드'   : [],\n",
    "                    '강의명'     : [],\n",
    "                    '학점'       : [],\n",
    "                    '총시간'     : [],\n",
    "                    '교수명'     : [],\n",
    "                    '강의실/시간': [],\n",
    "                    '강의평'     : [],\n",
    "                    '담은인원'   : [],\n",
    "                    '정원'       : [],\n",
    "                    '수강방법'   : [],\n",
    "                    'URL_ID'     : []\n",
    "                    }\n",
    "    num = []\n",
    "    for idx, tr in enumerate(tr_tag) :\n",
    "\n",
    "        td = tr.select('#subjects > div.list > table > tbody > tr > td')\n",
    "        a1 = tr.select('td:nth-child(9) > a')\n",
    "        a2 = a1[0].attrs['title']\n",
    "        a3 = a1[0].attrs['href'].split('/')[-1]\n",
    "        num.append(idx)\n",
    "\n",
    "        subjet_dict['학년'].append(td[0].text.strip()) \n",
    "        subjet_dict['구분'].append(td[1].text.strip()) \n",
    "        subjet_dict['과목코드'].append(td[2].text.strip())\n",
    "        subjet_dict['강의명'].append(td[3].text.strip())\n",
    "        subjet_dict['학점'].append(td[4].text.strip())\n",
    "        subjet_dict['총시간'].append(td[5].text.strip()) \n",
    "        subjet_dict['교수명'].append(td[6].text.strip())\n",
    "        subjet_dict['강의실/시간'].append(td[7].text.strip())\n",
    "        subjet_dict['강의평'].append(a2)\n",
    "        subjet_dict['담은인원'].append(td[9].text.strip())\n",
    "        subjet_dict['정원'].append(td[10].text.strip())\n",
    "        subjet_dict['수강방법'].append(td[11].text.strip()) \n",
    "        subjet_dict['URL_ID'].append(a3)\n",
    "\n",
    "    for s in soup.select('#subjects > div.filter > a.item.active > span.value') :\n",
    "        subjet_dict['학과'].append([s.text.strip()] * (num[-1] + 1) )\n",
    "\n",
    "    subjet_dict['학과'] = subjet_dict['학과'][0]\n",
    "\n",
    "    # 수집한 자료 저장.\n",
    "    df = pd.DataFrame(subjet_dict) \n",
    "\n",
    "    if os.path.exists('data.csv') == False :\n",
    "        df.to_csv('data.csv', encoding='utf-8-sig', index=False)  \n",
    "    else :\n",
    "        # 수집한 자료 추가하기.\n",
    "        df.to_csv('data.csv', encoding='utf-8-sig', index=False, header=None, mode='a')\n",
    "\n",
    "    name = subjet_dict['학과'][0]\n",
    "    print(f'{name} 데이터 저장완료')\n",
    "    print('=' * 130)\n",
    "\n",
    "    # 전공 재클릭.\n",
    "    driver.find_element_by_xpath('//*[@id=\"subjects\"]/div[1]/a[3]').click()\n",
    "    value = random.uniform(2, 5) \n",
    "    time.sleep(value)\n",
    "\n",
    "print('데이터 수집을 종료하였습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수집한 데이터 읽어 오기.\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# df2는 자연어 처리를 위한 댓글이 달린 데이터만 가져옴.\n",
    "df2 = df[df['강의평'] != 0]\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url_id 문자열 값으로 리스트 변환.\n",
    "url_id_List = list(map(str, df2['URL_ID'].values))\n",
    "\n",
    "# 같은 교수가 같은 과목을 2개 이상 강의 하는 경우가 다소 존재.\n",
    "# 즉, 데이터 중복을 고려하여 동일한 URL_ID 값 제거.\n",
    "url_id_List = set(url_id_List)\n",
    "len(url_id_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 수집 함수.\n",
    "def Information(url_id_List) :\n",
    "    Review_dict = {\n",
    "                    \"url_id\" : [],\n",
    "                    \"번호\"   : [],\n",
    "                    \"강의명\" : [],\n",
    "                    \"교수명\" : [],\n",
    "                    \"평점\"   : [],\n",
    "                    \"년도\"   : [],\n",
    "                    \"학기\"   : [],\n",
    "                    \"추천수\" : [],\n",
    "                    \"댓글\"   : []\n",
    "                }\n",
    "\n",
    "    for url_id in url_id_List :\n",
    "\n",
    "        # 선택 강의 경로로 넘어가기.\n",
    "        url = \"https://everytime.kr/lecture/view/\" + url_id\n",
    "        value = random.uniform(3, 5) \n",
    "        time.sleep(value)\n",
    "        driver.get(url)\n",
    "\n",
    "        time.sleep(3)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "        lecture_name = soup.select_one(\"#container > div.side.head > h2\").text\n",
    "        professor_name = soup.select_one(\"#container > div.side.head > p:nth-of-type(1) > span\").text\n",
    "        review_list = soup.select(\"article\")\n",
    "        # print(lecture_name, professor_name)\n",
    "        # print(review_list)\n",
    "\n",
    "        # 각 강의당 리뷰.\n",
    "        index = 0\n",
    "        for review in review_list :\n",
    "            if review.select_one('div.pay') == None : \n",
    "\n",
    "                rate = review.select_one('p.rate > span > span')[\"style\"]      \n",
    "                rate = float(rate[-5 : -2])                                \n",
    "                # print(rate)\n",
    "\n",
    "                semester = review.select_one('p.info > span.semester').text\n",
    "                year = int(semester[0:2])\n",
    "                semester = int(semester[4])\n",
    "                text = review.select_one('p.text').text\n",
    "                like = review.select_one(\"p.info > span.posvote\")\n",
    "                if like == None :\n",
    "                    like = 0\n",
    "                else :\n",
    "                    like = int(like.text)\n",
    "\n",
    "                Review_dict['url_id'].append(url_id)\n",
    "                Review_dict['번호'].append(index)\n",
    "                Review_dict['강의명'].append(lecture_name)\n",
    "                Review_dict['교수명'].append(professor_name)\n",
    "                Review_dict['평점'].append(rate)\n",
    "                Review_dict['년도'].append(year)\n",
    "                Review_dict['학기'].append(semester)\n",
    "                Review_dict['추천수'].append(like)\n",
    "                Review_dict['댓글'].append(text)\n",
    "\n",
    "                index += 1\n",
    "\n",
    "    # 데이터 프레임 생성.\n",
    "    df = pd.DataFrame(Review_dict)\n",
    "\n",
    "    # 댓글이 없는 데이터 자료 제거.\n",
    "    # df2 = df1[df1['평가 수준'] != 0]\n",
    "\n",
    "    if os.path.exists('review.csv') == False :\n",
    "        df.to_csv('review.csv', encoding='utf-8-sig', index=False)  \n",
    "    else :\n",
    "        df.to_csv('review.csv', encoding='utf-8-sig', index=False, header=False, mode='a')\n",
    "\n",
    "    print('저장 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 수집 시작.\n",
    "Information(url_id_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 종료.\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 데이터 불러와 데이터 확인.\n",
    "df3 = pd.read_csv('Data Collection/review.csv')\n",
    "pd.set_option('display.max_rows', None)\n",
    "df3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
